{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "action_spec: BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\nobservation_spec: BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n"
    }
   ],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = suite_gym.load(env_name)\n",
    "print('action_spec:', env.action_spec())\n",
    "print('observation_spec:', env.observation_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100,)\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, steps=100)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations. \n",
    "# For more details see the drivers module.\n",
    "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(Trajectory(step_type=<tf.Tensor: shape=(), dtype=int32, numpy=1>, observation=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.04742952, -0.55721486, -0.00206115,  0.7399192 ], dtype=float32)>, action=<tf.Tensor: shape=(), dtype=int64, numpy=0>, policy_info=(), next_step_type=<tf.Tensor: shape=(), dtype=int32, numpy=1>, reward=<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, discount=<tf.Tensor: shape=(), dtype=float32, numpy=1.0>),\n BufferInfo(ids=<tf.Tensor: shape=(), dtype=int64, numpy=28>, probabilities=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>))"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x14baccf10>\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(Trajectory(step_type=<tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n array([[1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 2],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [1, 2],\n        [1, 1],\n        [1, 2],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 2],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 0],\n        [1, 2],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [1, 2],\n        [1, 1],\n        [2, 0],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [2, 0],\n        [1, 1],\n        [1, 1],\n        [1, 1]], dtype=int32)>, observation=<tf.Tensor: shape=(64, 2, 4), dtype=float32, numpy=\n array([[[-4.99407053e-02, -4.50117350e-01,  1.60583749e-01,\n           9.81346011e-01],\n         [-5.89430556e-02, -6.46984398e-01,  1.80210680e-01,\n           1.31985629e+00]],\n \n        [[ 5.70590831e-02,  4.23647702e-01, -3.67313847e-02,\n          -5.88835120e-01],\n         [ 6.55320361e-02,  6.19264245e-01, -4.85080853e-02,\n          -8.92858565e-01]],\n \n        [[-9.30062011e-02, -1.19340825e+00,  1.10833563e-01,\n           1.78095162e+00],\n         [-1.16874367e-01, -9.99693990e-01,  1.46452591e-01,\n           1.52468145e+00]],\n \n        [[ 1.34792542e-02, -2.37536773e-01,  4.74215671e-02,\n           2.92607844e-01],\n         [ 8.72851815e-03, -4.31219004e-02,  5.32737263e-02,\n           1.52500849e-02]],\n \n        [[ 9.42175090e-02,  6.20805681e-01, -9.03729945e-02,\n          -9.29219484e-01],\n         [ 1.06633626e-01,  4.27012235e-01, -1.08957380e-01,\n          -6.66249096e-01]],\n \n        [[-1.53000489e-01, -6.14130020e-01,  2.02567473e-01,\n           1.04859853e+00],\n         [-1.65283099e-01, -8.11278582e-01,  2.23539442e-01,\n           1.39742315e+00]],\n \n        [[-3.01277395e-02,  4.11867291e-01, -3.26811001e-02,\n          -5.98991990e-01],\n         [-2.18903944e-02,  2.17217460e-01, -4.46609370e-02,\n          -3.16779673e-01]],\n \n        [[-7.55287707e-02, -6.24468565e-01,  6.41226098e-02,\n           8.97269189e-01],\n         [-8.80181417e-02, -4.30271745e-01,  8.20679963e-02,\n           6.25411749e-01]],\n \n        [[ 7.86608085e-03, -2.38965794e-01,  5.35787269e-02,\n           3.24254215e-01],\n         [ 3.08676460e-03, -4.34808075e-01,  6.00638129e-02,\n           6.33340716e-01]],\n \n        [[-4.65536751e-02,  1.40384749e-01,  1.41847119e-01,\n          -2.15379875e-02],\n         [-4.37459797e-02, -5.64563945e-02,  1.41416371e-01,\n           3.12321633e-01]],\n \n        [[ 7.48594180e-02,  1.16321170e+00, -8.62025544e-02,\n          -1.75811625e+00],\n         [ 9.81236473e-02,  9.69165504e-01, -1.21364877e-01,\n          -1.49343991e+00]],\n \n        [[ 7.79173225e-02,  8.15009356e-01, -6.63652569e-02,\n          -1.20038664e+00],\n         [ 9.42175090e-02,  6.20805681e-01, -9.03729945e-02,\n          -9.29219484e-01]],\n \n        [[ 1.14732357e-02, -2.17598364e-01, -4.03569937e-02,\n           3.05583626e-01],\n         [ 7.12126819e-03, -4.12122667e-01, -3.42453234e-02,\n           5.85270762e-01]],\n \n        [[-4.05901745e-02, -2.45640725e-01,  1.27856523e-01,\n           4.74669099e-01],\n         [-4.55029905e-02, -5.25342077e-02,  1.37349904e-01,\n           2.24861145e-01]],\n \n        [[-1.31301165e-01, -2.42666110e-01,  1.50435507e-01,\n           5.02004504e-01],\n         [-1.36154488e-01, -4.99490947e-02,  1.60475597e-01,\n           2.60255247e-01]],\n \n        [[ 5.24971299e-02,  2.28097662e-01, -3.10006198e-02,\n          -2.86538273e-01],\n         [ 5.70590831e-02,  4.23647702e-01, -3.67313847e-02,\n          -5.88835120e-01]],\n \n        [[ 1.19845085e-01,  4.03655171e-02, -1.30477622e-01,\n          -1.57995313e-01],\n         [ 1.20652393e-01,  2.37090707e-01, -1.33637533e-01,\n          -4.88826483e-01]],\n \n        [[ 5.24971299e-02,  2.28097662e-01, -3.10006198e-02,\n          -2.86538273e-01],\n         [ 5.70590831e-02,  4.23647702e-01, -3.67313847e-02,\n          -5.88835120e-01]],\n \n        [[-1.12118549e-03, -6.06748641e-01, -2.25399081e-02,\n           8.66972387e-01],\n         [-1.32561577e-02, -8.01556706e-01, -5.20046009e-03,\n           1.15248406e+00]],\n \n        [[-4.74170856e-02,  2.07775068e-02, -9.30050947e-03,\n           5.24926418e-03],\n         [-4.70015369e-02,  2.16031596e-01, -9.19552427e-03,\n          -2.90353507e-01]],\n \n        [[-4.99407053e-02, -4.50117350e-01,  1.60583749e-01,\n           9.81346011e-01],\n         [-5.89430556e-02, -6.46984398e-01,  1.80210680e-01,\n           1.31985629e+00]],\n \n        [[-4.43325713e-02,  2.03340836e-02, -1.56558622e-02,\n           1.50325708e-02],\n         [-4.39258888e-02, -1.74559891e-01, -1.53552108e-02,\n           3.02735060e-01]],\n \n        [[-8.80181417e-02, -4.30271745e-01,  8.20679963e-02,\n           6.25411749e-01],\n         [-9.66235772e-02, -2.36385554e-01,  9.45762321e-02,\n           3.59662175e-01]],\n \n        [[-7.30584487e-02, -9.97387409e-01,  8.15546215e-02,\n           1.46394706e+00],\n         [-9.30062011e-02, -1.19340825e+00,  1.10833563e-01,\n           1.78095162e+00]],\n \n        [[ 1.67588256e-02, -3.16578858e-02,  4.88435589e-02,\n           1.60272873e-03],\n         [ 1.61256678e-02,  1.62730783e-01,  4.88756150e-02,\n          -2.75278240e-01]],\n \n        [[-4.26809043e-02,  4.11283463e-01, -1.50025943e-02,\n          -5.85922360e-01],\n         [-3.44552360e-02,  2.16374815e-01, -2.67210416e-02,\n          -2.98002899e-01]],\n \n        [[ 7.12126819e-03, -4.12122667e-01, -3.42453234e-02,\n           5.85270762e-01],\n         [-1.12118549e-03, -6.06748641e-01, -2.25399081e-02,\n           8.66972387e-01]],\n \n        [[ 1.40817702e-01,  1.36198103e+00, -1.87662154e-01,\n          -2.15702033e+00],\n         [ 1.68057323e-01,  1.55838454e+00, -2.30802566e-01,\n          -2.50130248e+00]],\n \n        [[ 4.90916008e-03,  8.07598650e-01, -8.96108150e-02,\n          -1.30908942e+00],\n         [ 2.10611336e-02,  1.00373435e+00, -1.15792602e-01,\n          -1.62842286e+00]],\n \n        [[ 1.40817702e-01,  1.36198103e+00, -1.87662154e-01,\n          -2.15702033e+00],\n         [ 1.68057323e-01,  1.55838454e+00, -2.30802566e-01,\n          -2.50130248e+00]],\n \n        [[ 5.24971299e-02,  2.28097662e-01, -3.10006198e-02,\n          -2.86538273e-01],\n         [ 5.70590831e-02,  4.23647702e-01, -3.67313847e-02,\n          -5.88835120e-01]],\n \n        [[-4.92195003e-02, -1.19194746e+00,  4.67198603e-02,\n           1.74173808e+00],\n         [-7.30584487e-02, -9.97387409e-01,  8.15546215e-02,\n           1.46394706e+00]],\n \n        [[ 1.06633626e-01,  4.27012235e-01, -1.08957380e-01,\n          -6.66249096e-01],\n         [ 1.15173869e-01,  2.33560845e-01, -1.22282363e-01,\n          -4.09762889e-01]],\n \n        [[ 7.79173225e-02,  8.15009356e-01, -6.63652569e-02,\n          -1.20038664e+00],\n         [ 9.42175090e-02,  6.20805681e-01, -9.03729945e-02,\n          -9.29219484e-01]],\n \n        [[-1.53000489e-01, -6.14130020e-01,  2.02567473e-01,\n           1.04859853e+00],\n         [-1.65283099e-01, -8.11278582e-01,  2.23539442e-01,\n           1.39742315e+00]],\n \n        [[-1.04208607e-02, -4.36649561e-01,  7.99338669e-02,\n           6.74862862e-01],\n         [-1.91538520e-02, -6.32786036e-01,  9.34311226e-02,\n           9.91603732e-01]],\n \n        [[-1.10005602e-01, -6.29092932e-01,  1.15381584e-01,\n           1.00351572e+00],\n         [-1.22587457e-01, -4.35685545e-01,  1.35451898e-01,\n           7.49180496e-01]],\n \n        [[ 1.38889030e-01,  4.83576842e-02, -1.71345353e-01,\n          -3.37727726e-01],\n         [ 1.39856175e-01,  2.45450914e-01, -1.78099915e-01,\n          -6.79167688e-01]],\n \n        [[-2.00382583e-02,  2.19989330e-01, -4.84314300e-02,\n          -3.78031343e-01],\n         [-1.56384725e-02,  4.15764451e-01, -5.59920594e-02,\n          -6.85582936e-01]],\n \n        [[-4.39258888e-02, -1.74559891e-01, -1.53552108e-02,\n           3.02735060e-01],\n         [-4.74170856e-02,  2.07775068e-02, -9.30050947e-03,\n           5.24926418e-03]],\n \n        [[-6.69556856e-02, -4.28654134e-01,  5.23512959e-02,\n           5.88565648e-01],\n         [-7.55287707e-02, -6.24468565e-01,  6.41226098e-02,\n           8.97269189e-01]],\n \n        [[-1.42092571e-01, -4.43959594e-01,  1.77659586e-01,\n           9.38892722e-01],\n         [-1.50971755e-01, -6.40973926e-01,  1.96437433e-01,\n           1.28172028e+00]],\n \n        [[-1.63791239e-01, -4.48820055e-01,  2.22071841e-01,\n           1.05641460e+00],\n         [ 4.66648489e-02,  3.17900814e-02, -2.65957434e-02,\n           3.24256830e-02]],\n \n        [[-1.50971755e-01, -6.40973926e-01,  1.96437433e-01,\n           1.28172028e+00],\n         [-1.63791239e-01, -4.48820055e-01,  2.22071841e-01,\n           1.05641460e+00]],\n \n        [[-4.37459797e-02, -5.64563945e-02,  1.41416371e-01,\n           3.12321633e-01],\n         [-4.48751077e-02, -2.53280014e-01,  1.47662804e-01,\n           6.46047831e-01]],\n \n        [[-5.60939685e-03, -2.40573183e-01,  7.27306232e-02,\n           3.60161901e-01],\n         [-1.04208607e-02, -4.36649561e-01,  7.99338669e-02,\n           6.74862862e-01]],\n \n        [[-1.04208607e-02, -4.36649561e-01,  7.99338669e-02,\n           6.74862862e-01],\n         [-1.91538520e-02, -6.32786036e-01,  9.34311226e-02,\n           9.91603732e-01]],\n \n        [[-8.80181417e-02, -4.30271745e-01,  8.20679963e-02,\n           6.25411749e-01],\n         [-9.66235772e-02, -2.36385554e-01,  9.45762321e-02,\n           3.59662175e-01]],\n \n        [[ 2.10611336e-02,  1.00373435e+00, -1.15792602e-01,\n          -1.62842286e+00],\n         [ 4.11358215e-02,  8.10148418e-01, -1.48361057e-01,\n          -1.37395537e+00]],\n \n        [[ 7.48594180e-02,  1.16321170e+00, -8.62025544e-02,\n          -1.75811625e+00],\n         [ 9.81236473e-02,  9.69165504e-01, -1.21364877e-01,\n          -1.49343991e+00]],\n \n        [[ 4.66648489e-02,  3.17900814e-02, -2.65957434e-02,\n           3.24256830e-02],\n         [ 4.73006479e-02,  2.27283135e-01, -2.59472299e-02,\n          -2.68528432e-01]],\n \n        [[-7.18827397e-02, -4.54539120e-01,  2.06607804e-01,\n           1.08855867e+00],\n         [-8.09735209e-02, -2.62650311e-01,  2.28378966e-01,\n           8.67158413e-01]],\n \n        [[-5.60939685e-03, -2.40573183e-01,  7.27306232e-02,\n           3.60161901e-01],\n         [-1.04208607e-02, -4.36649561e-01,  7.99338669e-02,\n           6.74862862e-01]],\n \n        [[ 7.74743930e-02,  1.20343363e+00, -2.10022599e-01,\n          -2.05098391e+00],\n         [-4.05423567e-02, -3.70794348e-02,  1.86508987e-02,\n          -2.67989188e-02]],\n \n        [[ 7.79173225e-02,  8.15009356e-01, -6.63652569e-02,\n          -1.20038664e+00],\n         [ 9.42175090e-02,  6.20805681e-01, -9.03729945e-02,\n          -9.29219484e-01]],\n \n        [[-4.59332205e-02, -4.27839518e-01,  2.35491153e-02,\n           5.70050657e-01],\n         [-5.44900112e-02, -6.23283684e-01,  3.49501297e-02,\n           8.70058417e-01]],\n \n        [[-4.43325713e-02,  2.03340836e-02, -1.56558622e-02,\n           1.50325708e-02],\n         [-4.39258888e-02, -1.74559891e-01, -1.53552108e-02,\n           3.02735060e-01]],\n \n        [[ 4.00731005e-02,  7.71881223e-01, -3.43431085e-02,\n          -1.14486015e+00],\n         [ 5.55107258e-02,  9.67434525e-01, -5.72403111e-02,\n          -1.44811201e+00]],\n \n        [[-1.31301165e-01, -2.42666110e-01,  1.50435507e-01,\n           5.02004504e-01],\n         [-1.36154488e-01, -4.99490947e-02,  1.60475597e-01,\n           2.60255247e-01]],\n \n        [[-4.43325713e-02,  2.03340836e-02, -1.56558622e-02,\n           1.50325708e-02],\n         [-4.39258888e-02, -1.74559891e-01, -1.53552108e-02,\n           3.02735060e-01]],\n \n        [[-1.63791239e-01, -4.48820055e-01,  2.22071841e-01,\n           1.05641460e+00],\n         [ 4.66648489e-02,  3.17900814e-02, -2.65957434e-02,\n           3.24256830e-02]],\n \n        [[-3.18095721e-02, -4.39030141e-01,  1.13263197e-01,\n           7.29666293e-01],\n         [-4.05901745e-02, -2.45640725e-01,  1.27856523e-01,\n           4.74669099e-01]],\n \n        [[-1.04208607e-02, -4.36649561e-01,  7.99338669e-02,\n           6.74862862e-01],\n         [-1.91538520e-02, -6.32786036e-01,  9.34311226e-02,\n           9.91603732e-01]],\n \n        [[ 4.00731005e-02,  7.71881223e-01, -3.43431085e-02,\n          -1.14486015e+00],\n         [ 5.55107258e-02,  9.67434525e-01, -5.72403111e-02,\n          -1.44811201e+00]]], dtype=float32)>, action=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n array([[0, 1],\n        [1, 1],\n        [1, 1],\n        [1, 0],\n        [0, 0],\n        [0, 1],\n        [0, 0],\n        [1, 1],\n        [0, 1],\n        [0, 0],\n        [0, 1],\n        [0, 0],\n        [0, 0],\n        [1, 1],\n        [1, 0],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [0, 0],\n        [1, 1],\n        [0, 1],\n        [0, 1],\n        [1, 0],\n        [0, 1],\n        [1, 1],\n        [0, 1],\n        [0, 0],\n        [1, 1],\n        [1, 0],\n        [1, 1],\n        [1, 1],\n        [1, 0],\n        [0, 0],\n        [0, 0],\n        [0, 1],\n        [0, 1],\n        [1, 1],\n        [1, 0],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [0, 0],\n        [0, 0],\n        [0, 1],\n        [1, 0],\n        [0, 1],\n        [0, 1],\n        [1, 0],\n        [1, 1],\n        [0, 0],\n        [1, 0],\n        [0, 0],\n        [0, 1],\n        [0, 1],\n        [1, 1],\n        [1, 0],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [1, 1]])>, policy_info=(), next_step_type=<tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n array([[1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 0],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 0],\n        [1, 1],\n        [2, 0],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 0],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 2],\n        [0, 1],\n        [2, 0],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 0],\n        [1, 1],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [0, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1]], dtype=int32)>, reward=<tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n array([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 0.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 0.],\n        [1., 1.],\n        [1., 0.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 0.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 0.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 0.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]], dtype=float32)>, discount=<tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n array([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 0.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [0., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]], dtype=float32)>),\n BufferInfo(ids=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n array([[70, 71],\n        [40, 41],\n        [82, 83],\n        [57, 58],\n        [43, 44],\n        [85, 86],\n        [ 6,  7],\n        [24, 25],\n        [59, 60],\n        [67, 68],\n        [93, 94],\n        [42, 43],\n        [75, 76],\n        [65, 66],\n        [30, 31],\n        [39, 40],\n        [46, 47],\n        [39, 40],\n        [77, 78],\n        [ 2,  3],\n        [70, 71],\n        [ 0,  1],\n        [25, 26],\n        [81, 82],\n        [98, 99],\n        [ 4,  5],\n        [76, 77],\n        [96, 97],\n        [14, 15],\n        [96, 97],\n        [39, 40],\n        [80, 81],\n        [44, 45],\n        [42, 43],\n        [85, 86],\n        [62, 63],\n        [28, 29],\n        [50, 51],\n        [11, 12],\n        [ 1,  2],\n        [23, 24],\n        [33, 34],\n        [35, 36],\n        [34, 35],\n        [68, 69],\n        [61, 62],\n        [62, 63],\n        [25, 26],\n        [15, 16],\n        [93, 94],\n        [36, 37],\n        [72, 73],\n        [61, 62],\n        [18, 19],\n        [42, 43],\n        [21, 22],\n        [ 0,  1],\n        [91, 92],\n        [30, 31],\n        [ 0,  1],\n        [35, 36],\n        [64, 65],\n        [62, 63],\n        [91, 92]])>, probabilities=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n array([0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n        0.01010101, 0.01010101, 0.01010101, 0.01010101], dtype=float32)>))"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "\n",
    "print(iterator)\n",
    "iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "step = 200: loss = 32.98674774169922\nstep = 400: loss = 15.671080589294434\nstep = 600: loss = 18.220123291015625\nstep = 800: loss = 11.905176162719727\nstep = 1000: loss = 7.1379780769348145\nstep = 1000: Average Return = 20.399999618530273\nstep = 1200: loss = 64.95201110839844\nstep = 1400: loss = 78.74870300292969\nstep = 1600: loss = 50.48851776123047\nstep = 1800: loss = 48.417015075683594\nstep = 2000: loss = 39.600738525390625\nstep = 2000: Average Return = 34.0\nstep = 2200: loss = 64.48052978515625\nstep = 2400: loss = 62.384464263916016\nstep = 2600: loss = 28.90789031982422\nstep = 2800: loss = 25.10535430908203\nstep = 3000: loss = 24.83998680114746\nstep = 3000: Average Return = 39.70000076293945\nstep = 3200: loss = 20.31778907775879\nstep = 3400: loss = 23.356082916259766\nstep = 3600: loss = 73.4090576171875\nstep = 3800: loss = 36.049659729003906\nstep = 4000: loss = 4.9152116775512695\nstep = 4000: Average Return = 66.5\nstep = 4200: loss = 59.49445343017578\nstep = 4400: loss = 72.27003479003906\nstep = 4600: loss = 3.9692649841308594\nstep = 4800: loss = 62.88059616088867\nstep = 5000: loss = 13.053121566772461\nstep = 5000: Average Return = 116.0999984741211\nstep = 5200: loss = 30.719085693359375\nstep = 5400: loss = 41.727256774902344\nstep = 5600: loss = 39.9008674621582\nstep = 5800: loss = 104.04562377929688\nstep = 6000: loss = 40.02470779418945\nstep = 6000: Average Return = 156.0\nstep = 6200: loss = 84.07643127441406\nstep = 6400: loss = 62.50274658203125\nstep = 6600: loss = 240.0196533203125\nstep = 6800: loss = 62.00543212890625\nstep = 7000: loss = 92.51126098632812\nstep = 7000: Average Return = 187.89999389648438\nstep = 7200: loss = 6.641450881958008\nstep = 7400: loss = 374.3218078613281\nstep = 7600: loss = 25.15900421142578\nstep = 7800: loss = 190.73915100097656\nstep = 8000: loss = 72.599365234375\nstep = 8000: Average Return = 200.0\nstep = 8200: loss = 126.24520874023438\nstep = 8400: loss = 202.25790405273438\nstep = 8600: loss = 469.04644775390625\nstep = 8800: loss = 297.6794738769531\nstep = 9000: loss = 17.857181549072266\nstep = 9000: Average Return = 181.1999969482422\nstep = 9200: loss = 151.15000915527344\nstep = 9400: loss = 182.72352600097656\nstep = 9600: loss = 213.56997680664062\nstep = 9800: loss = 478.0745849609375\nstep = 10000: loss = 270.83819580078125\nstep = 10000: Average Return = 189.1999969482422\nstep = 10200: loss = 15.12643814086914\nstep = 10400: loss = 21.694496154785156\nstep = 10600: loss = 196.12037658691406\nstep = 10800: loss = 314.6103210449219\nstep = 11000: loss = 37.16167449951172\nstep = 11000: Average Return = 200.0\nstep = 11200: loss = 20.102245330810547\nstep = 11400: loss = 314.81072998046875\nstep = 11600: loss = 19.686784744262695\nstep = 11800: loss = 16.461339950561523\nstep = 12000: loss = 286.1041564941406\nstep = 12000: Average Return = 194.0\nstep = 12200: loss = 254.5689697265625\nstep = 12400: loss = 30.81404685974121\nstep = 12600: loss = 18.544435501098633\nstep = 12800: loss = 385.6170959472656\nstep = 13000: loss = 27.4112548828125\nstep = 13000: Average Return = 194.89999389648438\nstep = 13200: loss = 27.94747543334961\nstep = 13400: loss = 11.7356595993042\nstep = 13600: loss = 483.8499755859375\nstep = 13800: loss = 612.9024047851562\nstep = 14000: loss = 22.60579490661621\nstep = 14000: Average Return = 200.0\nstep = 14200: loss = 541.7312622070312\nstep = 14400: loss = 546.4989624023438\nstep = 14600: loss = 441.72857666015625\nstep = 14800: loss = 34.74724578857422\nstep = 15000: loss = 850.1875610351562\nstep = 15000: Average Return = 200.0\nstep = 15200: loss = 274.0655822753906\nstep = 15400: loss = 697.7012939453125\nstep = 15600: loss = 1480.7265625\nstep = 15800: loss = 3685.32861328125\nstep = 16000: loss = 44.9913330078125\nstep = 16000: Average Return = 200.0\nstep = 16200: loss = 698.5120239257812\nstep = 16400: loss = 25.281862258911133\nstep = 16600: loss = 19.75906753540039\nstep = 16800: loss = 859.0690307617188\nstep = 17000: loss = 815.083251953125\nstep = 17000: Average Return = 200.0\nstep = 17200: loss = 30.17056655883789\nstep = 17400: loss = 36.09246826171875\nstep = 17600: loss = 1192.40625\nstep = 17800: loss = 66.35552978515625\nstep = 18000: loss = 746.2361450195312\nstep = 18000: Average Return = 200.0\nstep = 18200: loss = 1243.3028564453125\nstep = 18400: loss = 290.882568359375\nstep = 18600: loss = 936.4262084960938\nstep = 18800: loss = 886.9981079101562\nstep = 19000: loss = 532.8064575195312\nstep = 19000: Average Return = 197.0\nstep = 19200: loss = 55.584861755371094\nstep = 19400: loss = 620.36572265625\nstep = 19600: loss = 26.37369728088379\nstep = 19800: loss = 17.86269187927246\nstep = 20000: loss = 75.34152221679688\nstep = 20000: Average Return = 200.0\n"
    }
   ],
   "source": [
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-ecc1979df081>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-ecc1979df081>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    .yplot.ylabel('Average R)turn.)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "pyp.ot.plot(iterations, returns)\n",
    ".yplot.ylabel('Average R)turn.)\n",
    "pyplot.xlabel('Iterati.ns')\n",
    "pyplot.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit48ab55c67191446ab6f17aa00e0ca628",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}